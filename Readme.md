
```markdown
# ğŸ§  Hybrid Graph-RAG Medical Assistant

[![Coverage Report](https://img.shields.io/badge/Test%20Coverage-View%20Report-blue)](https://yash2535.github.io/hybrid-graph-rag-medical-assistant/coverage/)
![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Neo4j](https://img.shields.io/badge/Neo4j-GraphDB-green)
![Qdrant](https://img.shields.io/badge/Qdrant-VectorDB-orange)
![Ollama](https://img.shields.io/badge/LLM-Ollama-black)

> ğŸ” **Live Test Coverage Dashboard**  
> https://yash2535.github.io/hybrid-graph-rag-medical-assistant/coverage/

---

## ğŸ“Œ Overview

The **Hybrid Graph-RAG Medical Assistant** is a privacy-preserving medical question-answering system that combines:

- ğŸ§© **Structured reasoning** using a Neo4j Knowledge Graph  
- ğŸ“š **Semantic retrieval** using Qdrant Vector Database  
- ğŸ§  **Local LLM inference** using Ollama  
- âš ï¸ **Safety validation layer** for medical reliability  

It integrates structured patient context with research paper embeddings to generate **safe, explainable, and auditable responses** â€” fully offline.

---

## âœ¨ Key Features

- ğŸ§  Hybrid Graph + Vector Retrieval
- ğŸ¥ Patient-specific reasoning using Neo4j
- ğŸ“„ Research-backed answers using semantic search
- âš ï¸ Drug interaction & safety checks
- ğŸ“Š Structured claims output for transparency
- ğŸ”’ Fully local execution (no cloud dependency)
- ğŸ§ª 300+ automated tests with coverage dashboard

---

## ğŸ—ï¸ High-Level Architecture

```

User Question
â”‚
â–¼
Neo4j Patient Graph â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”œâ”€â”€ Context Builder â”€â”€â”€â–º Local LLM (Ollama)
Qdrant Research Papers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
Safe + Structured Medical Response

```

---

## ğŸ§© Core Components

| Layer | Technology | Purpose |
|-------|------------|----------|
| Graph Database | Neo4j | Patient data, conditions, medications |
| Vector Database | Qdrant | Semantic research paper retrieval |
| Embeddings | BAAI/bge-m3 | Dense vector representation |
| LLM | phi3:mini (Ollama) | Local answer generation |
| Safety Layer | Custom logic | Drug interaction & red-flag checks |
| Testing | Pytest | 300+ automated tests |

---

## ğŸ“ Project Structure

```

hybrid-graph-rag-medical-assistant/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â””â”€â”€ graph_rag_pipeline.py
â”‚   â”œâ”€â”€ vector_store/
â”‚   â”‚   â”œâ”€â”€ qdrant_store.py
â”‚   â”‚   â””â”€â”€ paper_search.py
â”‚   â”œâ”€â”€ knowledge_graph/
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ embedding.py
â”‚   â”‚   â””â”€â”€ entity_extractor.py
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ ollama_client.py
â”‚   â”œâ”€â”€ routes/
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/coverage/          # GitHub Pages coverage report
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md

```

---

## âš™ï¸ Prerequisites

### 1ï¸âƒ£ Python
```

Python 3.9+

````

### 2ï¸âƒ£ Neo4j
- Neo4j Desktop or AuraDB
- Running on: `bolt://localhost:7687`

### 3ï¸âƒ£ Qdrant (Docker)

```bash
docker run -d -p 6333:6333 qdrant/qdrant
````

Check:

```
http://localhost:6333
```

### 4ï¸âƒ£ Ollama (Local LLM)

Install:
ğŸ‘‰ [https://ollama.com](https://ollama.com)

Pull lightweight model:

```bash
ollama pull phi3:mini
```

Verify:

```bash
ollama list
```

---

## ğŸ” Environment Variables

Create a `.env` file:

```env
# Neo4j
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=phi3:mini
```

---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv .venv
```

Activate:

**Windows**

```bash
.venv\Scripts\activate
```

**Linux / macOS**

```bash
source .venv/bin/activate
```

---

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Ensure Services Are Running

| Service | Status                                         |
| ------- | ---------------------------------------------- |
| Neo4j   | Running                                        |
| Qdrant  | [http://localhost:6333](http://localhost:6333) |
| Ollama  | `ollama serve`                                 |

---

## â–¶ï¸ Run the Full Pipeline

```bash
python -m app.rag.graph_rag_pipeline
```

Pipeline Steps:

1. Update patient graph
2. Retrieve patient profile
3. Retrieve wearable summaries
4. Retrieve research papers
5. Run drug interaction checks
6. Generate safe answer via LLM

---

## ğŸ§ª Run Tests

```bash
pytest tests/test_suite.py -v
```

Generate coverage:

```bash
pytest tests/test_suite.py --cov=app --cov-report=html:docs/coverage
```

ğŸ“Š Live coverage:
[https://yash2535.github.io/hybrid-graph-rag-medical-assistant/coverage/](https://yash2535.github.io/hybrid-graph-rag-medical-assistant/coverage/)

---

## ğŸ“Œ Sample Output

```
===== FINAL ANSWER =====
Personalized medical guidance

===== STRUCTURED CLAIMS =====
- Risk assessment
- Monitoring advice
- Emergency warning signs
```

---

## ğŸš¨ System Requirements

| Model     | RAM Requirement |
| --------- | --------------- |
| phi3:mini | ~3GB            |
| llama3    | >4.6GB          |

For 8GB systems â†’ **phi3:mini recommended**

---

## ğŸ”® Future Improvements

* GPU acceleration
* Sparse + dense hybrid retrieval
* Clinical citation linking (PMID)
* Web UI (React / Streamlit)
* FHIR-compatible patient records
* CI/CD auto coverage deployment

---

## ğŸ“œ Disclaimer

This system is for **educational and research purposes only**.
It does not replace professional medical advice, diagnosis, or treatment.

---

## ğŸ‘¨â€ğŸ’» Author

**Yash Jagdale**
AI Systems | Graph RAG | Healthcare AI | Mainframe + AI Hybrid Systems

````

---

# ğŸš€ After Updating

Run:

```bash
git add README.md
git commit -m "Refactor README with structured professional format"
git push origin main
````

---

Your repository will now look:

âœ” Structured
âœ” Professional
âœ” Recruiter-ready
âœ” Research-grade
âœ” Portfolio-strong

---

If you'd like next-level polish, I can:

* Add architecture diagram image
* Add system flow diagram (PNG)
* Add CI badge
* Add project maturity level section
* Make it conference-paper style

Just tell me ğŸ‘Œ
